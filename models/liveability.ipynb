{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/matthewproctor/australianpostcodes/master/australian_postcodes.csv'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('../data/raw//externel/australian_postcodes.csv', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"files saved as 'australian_postcodes.csv'\")\n",
    "else:\n",
    "    print(f\"download failed: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this part is used to re calculate the population by postcode\n",
    "\n",
    "data = pd.read_csv('../data/raw//externel/australian_postcodes.csv')\n",
    "### selected the VIC postcodes\n",
    "data = data[data['state'] == 'VIC']\n",
    "### get the useful columns\n",
    "selected_columns = ['postcode', 'locality', 'long', 'lat', 'SA2_NAME_2021']\n",
    "data = data[selected_columns]\n",
    "### drop empty values and save\n",
    "data = data.dropna()\n",
    "data.to_csv('../data/curated/external/vic_postcodes.csv')\n",
    "\n",
    "### read sa2 file\n",
    "pop = pd.read_csv('../data/curated/external/SA2/sa2final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine postcode and sa2 \n",
    "merged_data = pd.merge(data, pop, left_on='SA2_NAME_2021', right_on='SA2 name',how='right')\n",
    "### deal with some missing values\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Alfredton', 'postcode'] = 3350\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Canadian - Mount Clear', 'postcode'] = 3350\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Ballarat', 'postcode'] = 3350\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Smythes Creek', 'postcode'] = 3351\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Ballarat North - Invermay', 'postcode'] = 3352\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Ballarat East - Warrenheip', 'postcode'] = 3352\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Bacchus Marsh Surrounds', 'postcode'] = 3340\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Creswick - Clunes', 'postcode'] = 3363\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Maryborough', 'postcode'] = 3465\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Bendigo', 'postcode'] = 3350\n",
    "merged_data.loc[merged_data['SA2 name'] == 'California Gully - Eaglehawk', 'postcode'] = 3350\n",
    "merged_data.loc[merged_data['SA2 name'] == 'East Bendigo - Kennington', 'postcode'] = 3350\n",
    "merged_data.loc[merged_data['SA2 name'] == 'Flora Hill - Spring Gully', 'postcode'] = 3350\n",
    "merged_data = merged_data.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the postcode population and save data\n",
    "summed_data = merged_data.groupby('postcode').agg({\n",
    "    '2021 popluation': 'sum',\n",
    "    '2022 popluation': 'sum',\n",
    "    '2023 popluation': 'sum'\n",
    "}).reset_index()\n",
    "summed_data.to_csv('../data/curated/SA2/postcode_pop.csv')\n",
    "summed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start liveavility and affordablity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = '../data/curated/external/cleaned_final_data.csv'  \n",
    "data_ = pd.read_csv(file_path)\n",
    "cols_drop = ['beds','baths','parking','SA2_CODE_2021','SA2_NAME_2021','2021 popluation','2022 popluation','2023 popluation']\n",
    "data_ = data_.drop(columns=cols_drop)\n",
    "pp = pd.read_csv('../data/curated/SA2/postcode_pop.csv')\n",
    "\n",
    "df_1 = pd.merge(data_, pp, on='postcode',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### affordability \n",
    "df_1['affordability_ratio'] = (df_1['price']  / df_1['Median_tot_prsnl_inc_weekly']*0.3)\n",
    "\n",
    "### number of crimes per 100,000 people\n",
    "df_1['crime_rate_21'] = (df_1['2021crime'] / df_1['2021 popluation']) * 100000\n",
    "df_1['crime_rate_22'] = (df_1['2022crime'] / df_1['2022 popluation']) * 100000\n",
    "df_1['crime_rate_23'] = (df_1['2023crime'] / df_1['2023 popluation']) * 100000\n",
    "df_1['total_crime_rate'] = df_1['crime_rate_21'] + df_1['crime_rate_22'] + df_1['crime_rate_23']\n",
    "df_1 = df_1.dropna()\n",
    "df_1 = df_1[~df_1.isin([np.inf, -np.inf]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "### standardies distance \n",
    "distance_columns = ['minimum_distance_school', 'minimum_distance_police', \n",
    "                    'minimum_distance_station', 'minimum_distance_supermarket', \n",
    "                    'minimum_distance_library']\n",
    "df_1[distance_columns] = scaler.fit_transform(df[distance_columns])\n",
    "\n",
    "### get the weight \n",
    "distance_weights = {\n",
    "    'minimum_distance_school': 0.2,\n",
    "    'minimum_distance_police': 0.25,     \n",
    "    'minimum_distance_station': 0.2,    \n",
    "    'minimum_distance_supermarket': 0.15,\n",
    "    'minimum_distance_library': 0.2    \n",
    "}\n",
    "\n",
    "### standardies crime counts\n",
    "df_1['total_crime_rate'] = df_1['total_crime_rate'].astype(np.float64)\n",
    "df_1['total_crime_rate'] = scaler.fit_transform(df_1[['total_crime_rate']])\n",
    "df_1['crime_score'] = 1 - df_1['total_crime_rate']  \n",
    "\n",
    "### weight the crime rate\n",
    "livability_score = sum(df_1[col] * weight for col, weight in distance_weights.items()) + df_1['crime_score'] * 0.25\n",
    "livability_score = livability_score / (sum(distance_weights.values()) + 1)  \n",
    "df_1['livability_score'] = livability_score\n",
    "\n",
    "\n",
    "df_1['affordability_score'] = scaler.fit_transform(df_1[['affordability_ratio']])\n",
    "df_1['affordability_score'] = 1 - df_1['affordability_score']  \n",
    "\n",
    "df_1['combined_score'] = (df_1['livability_score']* 0.5 + df_1['affordability_score'] * 0.5)\n",
    "\n",
    "df_1.to_csv('../data/curated/combine_score.csv')\n",
    "\n",
    "### get top 10\n",
    "top_10 = df_1.sort_values(by='combined_score', ascending=False)\n",
    "top_10 = top_10.drop_duplicates('Suburb')\n",
    "top_10[['Suburb', 'livability_score','affordability_score', 'combined_score']].iloc[0:10]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
