{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Suburb\n",
      "0    Albert Park-Middle Park-West St Kilda\n",
      "1                                 Armadale\n",
      "2                            Carlton North\n",
      "3                        Carlton-Parkville\n",
      "4                          CBD-St Kilda Rd\n",
      "..                                     ...\n",
      "153                              Traralgon\n",
      "154                            Wanagaratta\n",
      "155                               Warragul\n",
      "156                            Warrnambool\n",
      "157                                Wodonga\n",
      "\n",
      "[146 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list containing Suburb names\n",
    "suburb_list = [\n",
    "    'Albert Park-Middle Park-West St Kilda', 'Armadale', 'Carlton North', 'Carlton-Parkville',\n",
    "    'CBD-St Kilda Rd', 'Collingwood-Abbotsford', 'Docklands', 'East Melbourne', 'East St Kilda',\n",
    "    'Elwood', 'Fitzroy', 'Fitzroy North-Clifton Hill', 'Flemington-Kensington',\n",
    "    'North Melbourne-West Melbourne', 'Port Melbourne', 'Prahran-Windsor', 'Richmond-Burnley',\n",
    "    'South Melbourne', 'South Yarra', 'Southbank', 'St Kilda', 'Toorak', 'Group Total', 'Balwyn',\n",
    "    'Blackburn', 'Box Hill', 'Bulleen-Templestowe-Doncaster', 'Burwood-Ashburton', 'Camberwell-Glen Iris',\n",
    "    'Canterbury-Surrey Hills-Mont Albert', 'Chadstone-Oakleigh', 'Clayton', 'Doncaster East-Donvale',\n",
    "    'East Hawthorn', 'Glen Waverley-Mulgrave', 'Hawthorn', 'Kew', 'Mount Waverley', 'Nunawading-Mitcham',\n",
    "    'Vermont-Forest Hill-Burwood East', 'Group Total', 'Aspendale-Chelsea-Carrum', 'Bentleigh', 'Brighton',\n",
    "    'Brighton East', 'Carnegie', 'Caulfield', 'Cheltenham', 'Elsternwick', 'Hampton-Beaumaris', 'Malvern',\n",
    "    'Malvern East', 'Mentone-Parkdale-Mordialloc', 'Murrumbeena-Hughesdale', 'Group Total', 'Altona',\n",
    "    'Footscray', 'Keilor East-Avondale Heights', 'Melton', 'Newport-Spotswood', 'St Albans-Deer Park',\n",
    "    'Sunshine', 'Sydenham', 'Werribee-Hoppers Crossing', 'West Footscray', 'Williamstown', 'Yarraville-Seddon',\n",
    "    'Group Total', 'Broadmeadows-Roxburgh Park', 'Brunswick', 'Coburg-Pascoe Vale South', 'Craigieburn',\n",
    "    'East Brunswick', 'Essendon', 'Gladstone Park-Tullamarine', 'Keilor', 'Moonee Ponds-Ascot Vale',\n",
    "    'Oak Park-Glenroy-Fawkner', 'Pascoe Vale-Coburg North', 'Sunbury', 'West Brunswick', 'Group Total',\n",
    "    'Bundoora-Greensborough-Hurstbridge', 'Eltham-Research-Montmorency', 'Fairfield-Alphington',\n",
    "    'Heidelberg-Heidelberg West', 'Ivanhoe-Ivanhoe East', 'Mill Park-Epping', 'Northcote', 'Preston',\n",
    "    'Reservoir', 'Thomastown-Lalor', 'Thornbury', 'Whittlesea', 'Group Total', 'Bayswater', 'Boronia',\n",
    "    'Croydon-Lilydale', 'Ferntree Gully', 'Ringwood', 'Rowville', 'Wantirna-Scoresby', 'Yarra Ranges',\n",
    "    'Group Total', 'Berwick', 'Cranbourne', 'Dandenong', 'Dandenong North-Endeavour Hills', \n",
    "    'Narre Warren-Hampton Park', 'Noble Park', 'Pakenham', 'Springvale', 'Group Total', 'Dromana-Portsea', \n",
    "    'Frankston', 'Hastings-Flinders', 'Mt Eliza-Mornington-Mt Martha', 'Seaford-Carrum Downs', 'Group Total', \n",
    "    'Belmont-Grovedale', 'Corio', 'Geelong-Newcombe', 'Herne Hill-Geelong West', 'Lara', 'Newtown', \n",
    "    'North Geelong', 'Group Total', 'Ballarat', 'Mount Clear-Buninyong', 'Sebastopol-Delacombe', \n",
    "    'Wendouree-Alfredton', 'Group Total', 'Bendigo', 'Flora Hill-Bendigo East', 'Golden Square-Kangaroo Flat',\n",
    "    'North Bendigo', 'Group Total', 'Bairnsdale', 'Benalla', 'Castlemaine', 'Echuca', 'Hamilton', 'Horsham',\n",
    "    'Mildura', 'Moe-Newborough', 'Morwell', 'Ocean Grove-Barwon Heads', 'Portland', 'Sale-Maffra', 'Seymour',\n",
    "    'Shepparton', 'Swan Hill', 'Torquay', 'Traralgon', 'Wanagaratta', 'Warragul', 'Warrnambool', 'Wodonga',\n",
    "    'Group Total'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(suburb_list, columns=['Suburb'])\n",
    "\n",
    "# Remove rows containing 'Group Total'\n",
    "filtered_df = df[~df['Suburb'].str.contains('Group Total')]\n",
    "\n",
    "print(filtered_df)\n",
    "\n",
    "filtered_df.to_csv(\"../data/curated/external/price_all_properties.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lijialan Wang\\AppData\\Local\\Temp\\ipykernel_20580\\3720637026.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  price = row[i+1]  # Median price is the column right after the date column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Suburb      Date Average Rent Price\n",
      "0  Albert Park-Middle Park-West St Kilda  Mar 2000                165\n",
      "1                               Armadale  Mar 2000                150\n",
      "2                          Carlton North  Mar 2000                150\n",
      "3                      Carlton-Parkville  Mar 2000                165\n",
      "4                        CBD-St Kilda Rd  Mar 2000                250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file_path = \"../data/raw/external/Moving annual rent by suburb - March quarter 2023.xlsx\"\n",
    "excel_data = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Initialize an empty DataFrame for the cleaned data\n",
    "cleaned_data = pd.DataFrame(columns=['Suburb', 'Date', 'Average Rent Price'])\n",
    "\n",
    "# Iterate through the columns to extract date and corresponding median rent price\n",
    "rows_list = []  # List to store row data\n",
    "for i in range(2, len(excel_data.columns), 2):  # Skip first two columns, step every two columns (date, median price)\n",
    "    date_label = excel_data.iloc[0, i]  # The date label is stored in the first row of each date column\n",
    "    for index, row in excel_data.iterrows():\n",
    "        suburb = row['Unnamed: 1']\n",
    "        if pd.isna(suburb) or suburb.strip() == '':\n",
    "            continue  # Skip rows without a suburb name\n",
    "        price = row[i+1]  # Median price is the column right after the date column\n",
    "        rows_list.append({'Suburb': suburb, 'Date': date_label, 'Average Rent Price': price})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "cleaned_data = pd.DataFrame(rows_list)\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "print(cleaned_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Inner Melbourne Albert Park-Middle Park-West St Kilda  1143  260  1134  \\\n",
      "0             NaN                              Armadale   733  200   737   \n",
      "1             NaN                         Carlton North   864  260   814   \n",
      "2             NaN                     Carlton-Parkville  1339  260  1304   \n",
      "3             NaN                       CBD-St Kilda Rd  2132  320  2264   \n",
      "4             NaN                Collingwood-Abbotsford   652  230   653   \n",
      "\n",
      "   260.1  1177  270  1178  275  ...    867 500.5  855.1  515    881 500.6  \\\n",
      "0    200   738  205   739  210  ...    805   430    851  450    852   450   \n",
      "1    260   799  265   736  270  ...    581   580    535  595    547   600   \n",
      "2    260  1300  260  1320  260  ...   6143   310   6018  319   6871   340   \n",
      "3    320  2358  320  2361  320  ...  17845   365  16792  390  18284   419   \n",
      "4    230   700  240   709  240  ...   2353   430   2307  450   2517   480   \n",
      "\n",
      "     832  525    786  545  \n",
      "0    840  460    751  490  \n",
      "1    546  600    490  620  \n",
      "2   6627  350   6690  400  \n",
      "3  17627  450  17426  500  \n",
      "4   2365  495   2163  520  \n",
      "\n",
      "[5 rows x 188 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the 'All properties' sheet from the Excel file\n",
    "file_path = \"../data/raw/external/Moving annual rent by suburb - March quarter 2023.xlsx\"\n",
    "sheet_name = 'All properties'\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=3)  # Skip the first 3 rows\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Suburb  Mar 2021\n",
      "0    Albert Park-Middle Park-West St Kilda       500\n",
      "1                                 Armadale       450\n",
      "2                            Carlton North       580\n",
      "3                        Carlton-Parkville       350\n",
      "4                          CBD-St Kilda Rd       380\n",
      "..                                     ...       ...\n",
      "141                              Traralgon       330\n",
      "142                            Wanagaratta       320\n",
      "143                               Warragul       375\n",
      "144                            Warrnambool       350\n",
      "145                                Wodonga       340\n",
      "\n",
      "[146 rows x 2 columns]\n",
      "CSV file saved to D:/STUDYfile/ADS/P2/notebook/data2/price_postcode.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lijialan Wang\\AppData\\Local\\Temp\\ipykernel_20580\\363655410.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  key = row[1]  # 第二列的值作为 key (suburb)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"../data/raw/external/Moving annual rent by suburb - March quarter 2023.xlsx\"\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read the \"All properties\" sheet\n",
    "sheet_name = \"All properties\"\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Initialize flags\n",
    "isYear = False\n",
    "isKeyword = False\n",
    "searchYear = \"Mar 2021\"\n",
    "searKeyword = \"Median\"\n",
    "columnIndex = 0\n",
    "\n",
    "# Find the column index for the specified year and keyword\n",
    "for column_name, column_data in df.items():\n",
    "    res = column_data.to_string(index=False)\n",
    "    if searchYear in res:\n",
    "        isYear = True\n",
    "    if isYear and searKeyword in res:\n",
    "        isKeyword = True\n",
    "    if isKeyword and isYear:\n",
    "        # Get the index of the target column\n",
    "        columnIndex = df.columns.get_loc(column_name)\n",
    "        break\n",
    "\n",
    "if columnIndex == 0:\n",
    "    print(\"No column found\")\n",
    "    exit(0)\n",
    "\n",
    "# Store key-value pairs in a dictionary\n",
    "data_dict = {}\n",
    "\n",
    "# Iterate through each row, using the second column as the key (suburb) and the target column's value as the value\n",
    "for index, row in df.iterrows():\n",
    "    key = row[1]  # Use the value from the second column as the key (suburb)\n",
    "    if pd.isna(key) or key == \"Group Total\":\n",
    "        continue\n",
    "    value = row.iloc[columnIndex]  # Value from the target column\n",
    "    data_dict[key] = value\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "result_df = pd.DataFrame(list(data_dict.items()), columns=[\"Suburb\", searchYear])\n",
    "\n",
    "# Print the result to confirm\n",
    "print(result_df)\n",
    "\n",
    "# Save the result as a CSV file\n",
    "output_file_path = \"../data/curated/external/price_postcode.csv\"\n",
    "result_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lijialan Wang\\AppData\\Local\\Temp\\ipykernel_20580\\2504779392.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  key = row[1]  # 第二列的值作为 key (suburb)\n",
      "C:\\Users\\Lijialan Wang\\AppData\\Local\\Temp\\ipykernel_20580\\2504779392.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if pd.isna(row[1]) or row[1] == \"Group Total\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Suburb  Mar 2021  Jun 2021  Sep 2021  \\\n",
      "0    Albert Park-Middle Park-West St Kilda       500       500       500   \n",
      "1                                 Armadale       450       440       425   \n",
      "2                            Carlton North       580       575       575   \n",
      "3                        Carlton-Parkville       350       340       330   \n",
      "4                          CBD-St Kilda Rd       380       369       350   \n",
      "..                                     ...       ...       ...       ...   \n",
      "141                              Traralgon       330       340       350   \n",
      "142                            Wanagaratta       320       330       350   \n",
      "143                               Warragul       375       380       390   \n",
      "144                            Warrnambool       350       360       370   \n",
      "145                                Wodonga       340       350       360   \n",
      "\n",
      "     Dec 2021  Mar 2022  Jun 2022  Sep 2022  Dec 2022  Mar 2023  \n",
      "0         495       500       515       500       525       545  \n",
      "1         420       430       450       450       460       490  \n",
      "2         580       580       595       600       600       620  \n",
      "3         320       310       319       340       350       400  \n",
      "4         350       365       390       419       450       500  \n",
      "..        ...       ...       ...       ...       ...       ...  \n",
      "141       360       360       380       380       380       385  \n",
      "142       360       370       380       380       380       380  \n",
      "143       390       400       400       420       430       440  \n",
      "144       380       400       400       420       420       420  \n",
      "145       370       380       390       400       410       410  \n",
      "\n",
      "[146 rows x 10 columns]\n",
      "CSV file saved to D:/STUDYfile/ADS/P2/notebook/data2/price_suburb.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"../data/raw/external/Moving annual rent by suburb - March quarter 2023.xlsx\"\n",
    "sheet_name = \"All properties\"\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Specify the list of years to extract\n",
    "searchYears = [\"Mar 2021\", \"Jun 2021\", \"Sep 2021\", \"Dec 2021\", \"Mar 2022\", \"Jun 2022\", \"Sep 2022\", \"Dec 2022\", \"Mar 2023\"]\n",
    "searKeyword = \"Median\"\n",
    "\n",
    "# Store the final data result\n",
    "data_dict = {\"Suburb\": []}  # First column is Suburb\n",
    "\n",
    "# Iterate over each year and extract corresponding columns\n",
    "for searchYear in searchYears:\n",
    "    isYear = False\n",
    "    isKeyword = False\n",
    "    columnIndex = 0\n",
    "\n",
    "    # Find the column index for the specified year and keyword\n",
    "    for column_name, column_data in df.items():\n",
    "        res = column_data.to_string(index=False)\n",
    "        if searchYear in res:\n",
    "            isYear = True\n",
    "        if isYear and searKeyword in res:\n",
    "            isKeyword = True\n",
    "        if isKeyword and isYear:\n",
    "            # Get the index of the target column\n",
    "            columnIndex = df.columns.get_loc(column_name)\n",
    "            break\n",
    "\n",
    "    if columnIndex == 0:\n",
    "        print(f\"No column found for {searchYear}\")\n",
    "        continue\n",
    "\n",
    "    # If it's the first extraction, fill the Suburb column\n",
    "    if not data_dict[\"Suburb\"]:\n",
    "        for index, row in df.iterrows():\n",
    "            key = row[1]  # Use the value from the second column as the key (suburb)\n",
    "            if pd.isna(key) or key == \"Group Total\":\n",
    "                continue\n",
    "            data_dict[\"Suburb\"].append(key)  # Fill the Suburb\n",
    "\n",
    "    # Create a new column for the current year\n",
    "    data_dict[searchYear] = []\n",
    "\n",
    "    # Iterate over each row, extracting the target column's value as the data\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row[1]) or row[1] == \"Group Total\":\n",
    "            continue\n",
    "        value = row.iloc[columnIndex]  # Value from the target column\n",
    "        data_dict[searchYear].append(value)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "result_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Print the result to confirm\n",
    "print(result_df)\n",
    "\n",
    "# Save the result as a CSV file\n",
    "output_file_path = \"../data/curated/external/price_suburb.csv\"\n",
    "result_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\STUDYfile\\\\ADS\\\\P2\\\\notebook\\\\data2\\\\expanded_price_suburb_v2.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/curated/external/price_suburb.csv\")\n",
    "\n",
    "\n",
    "# Split the suburbs with delimiter '-' into multiple rows as requested\n",
    "split_rows = data['Suburb'].str.split('-', expand=True)\n",
    "\n",
    "# Flattening the split rows into a single column, maintaining corresponding values for each row\n",
    "expanded_df = pd.DataFrame()\n",
    "\n",
    "for i in range(split_rows.shape[1]):  # iterate over columns produced by split\n",
    "    temp_df = data.copy()\n",
    "    temp_df['Suburb'] = split_rows[i]\n",
    "    temp_df = temp_df.dropna(subset=['Suburb'])  # drop empty Suburb rows (resulting from split)\n",
    "    expanded_df = pd.concat([expanded_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Save the newly expanded data to CSV\n",
    "output_file_path = \"../data/curated/external/expanded_price_suburb_v2.csv\"\n",
    "expanded_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Provide the path to the user for download\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://github.com/Elkfox/Australian-Postcode-Data/blob/master/au_postcodes.csv'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('../data/raw//externel/au_postcodes.csv', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"files saved as 'au_postcodes.csv'\")\n",
    "else:\n",
    "    print(f\"download failed: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw//externel/au_postcodes.csv')\n",
    "data = data[data['state'] == 'VIC']\n",
    "data.to_csv('../data/raw/external/au_postcodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>place_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-37.8140</td>\n",
       "      <td>144.9633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-37.8140</td>\n",
       "      <td>144.9633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3002</td>\n",
       "      <td>East Melbourne</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-37.8167</td>\n",
       "      <td>144.9879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3003</td>\n",
       "      <td>West Melbourne</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-37.8101</td>\n",
       "      <td>144.9500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-37.8140</td>\n",
       "      <td>144.9633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>3995</td>\n",
       "      <td>St Clair</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-38.5752</td>\n",
       "      <td>145.5665</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>3995</td>\n",
       "      <td>Wonthaggi</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-38.6059</td>\n",
       "      <td>145.5936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>3995</td>\n",
       "      <td>Cape Paterson</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-38.6709</td>\n",
       "      <td>145.6213</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>3996</td>\n",
       "      <td>Pound Creek</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-38.6333</td>\n",
       "      <td>145.8000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>3996</td>\n",
       "      <td>Inverloch</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>VIC</td>\n",
       "      <td>-38.6266</td>\n",
       "      <td>145.7226</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3224 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postcode      place_name state_name state_code  latitude  longitude  \\\n",
       "0         3000       Melbourne   Victoria        VIC  -37.8140   144.9633   \n",
       "1         3001       Melbourne   Victoria        VIC  -37.8140   144.9633   \n",
       "2         3002  East Melbourne   Victoria        VIC  -37.8167   144.9879   \n",
       "3         3003  West Melbourne   Victoria        VIC  -37.8101   144.9500   \n",
       "4         3004       Melbourne   Victoria        VIC  -37.8140   144.9633   \n",
       "...        ...             ...        ...        ...       ...        ...   \n",
       "3219      3995        St Clair   Victoria        VIC  -38.5752   145.5665   \n",
       "3220      3995       Wonthaggi   Victoria        VIC  -38.6059   145.5936   \n",
       "3221      3995   Cape Paterson   Victoria        VIC  -38.6709   145.6213   \n",
       "3222      3996     Pound Creek   Victoria        VIC  -38.6333   145.8000   \n",
       "3223      3996       Inverloch   Victoria        VIC  -38.6266   145.7226   \n",
       "\n",
       "      accuracy  \n",
       "0            4  \n",
       "1            4  \n",
       "2            4  \n",
       "3            4  \n",
       "4            4  \n",
       "...        ...  \n",
       "3219         3  \n",
       "3220         4  \n",
       "3221         4  \n",
       "3222         4  \n",
       "3223         4  \n",
       "\n",
       "[3224 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode = pd.read_csv(\"../data/raw/external/au_postcodes.csv\")\n",
    "df = pd.read_csv(\"../data/curated/external/expanded_price_suburb_v2.csv\")\n",
    "postcode = postcode.iloc[0:3224]\n",
    "postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Suburb'] == 'CBD', 'Suburb'] = 'Melbourne'\n",
    "postcode['postcode'] = postcode['postcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### stanardize name function\n",
    "def standardize_name(name):\n",
    "    # Convert to lowercase and sort alphabetically\n",
    "    return ' '.join(sorted(name.lower().split()))\n",
    "\n",
    "df['Standardized_Suburb'] = df['Suburb'].apply(standardize_name)\n",
    "postcode['Standardized_Suburb'] = postcode['place_name'].apply(standardize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge the data\n",
    "merged_df = pd.merge(df, postcode[['Standardized_Suburb', 'postcode']], on='Standardized_Suburb', how='left')\n",
    "merged_df = merged_df.drop(columns=['Standardized_Suburb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Mar 2021</th>\n",
       "      <th>Jun 2021</th>\n",
       "      <th>Sep 2021</th>\n",
       "      <th>Dec 2021</th>\n",
       "      <th>Mar 2022</th>\n",
       "      <th>Jun 2022</th>\n",
       "      <th>Sep 2022</th>\n",
       "      <th>Dec 2022</th>\n",
       "      <th>Mar 2023</th>\n",
       "      <th>postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yarra Ranges</td>\n",
       "      <td>400</td>\n",
       "      <td>415</td>\n",
       "      <td>420</td>\n",
       "      <td>425</td>\n",
       "      <td>433</td>\n",
       "      <td>450</td>\n",
       "      <td>460</td>\n",
       "      <td>460</td>\n",
       "      <td>478</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Mt Eliza</td>\n",
       "      <td>520</td>\n",
       "      <td>545</td>\n",
       "      <td>550</td>\n",
       "      <td>570</td>\n",
       "      <td>590</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Wanagaratta</td>\n",
       "      <td>320</td>\n",
       "      <td>330</td>\n",
       "      <td>350</td>\n",
       "      <td>360</td>\n",
       "      <td>370</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>St Kilda Rd</td>\n",
       "      <td>380</td>\n",
       "      <td>369</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>365</td>\n",
       "      <td>390</td>\n",
       "      <td>419</td>\n",
       "      <td>450</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Newcombe</td>\n",
       "      <td>360</td>\n",
       "      <td>370</td>\n",
       "      <td>375</td>\n",
       "      <td>380</td>\n",
       "      <td>394</td>\n",
       "      <td>400</td>\n",
       "      <td>410</td>\n",
       "      <td>420</td>\n",
       "      <td>425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Mt Martha</td>\n",
       "      <td>520</td>\n",
       "      <td>545</td>\n",
       "      <td>550</td>\n",
       "      <td>570</td>\n",
       "      <td>590</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Suburb  Mar 2021  Jun 2021  Sep 2021  Dec 2021  Mar 2022  Jun 2022  \\\n",
       "98   Yarra Ranges       400       415       420       425       433       450   \n",
       "110      Mt Eliza       520       545       550       570       590       600   \n",
       "155   Wanagaratta       320       330       350       360       370       380   \n",
       "162   St Kilda Rd       380       369       350       350       365       390   \n",
       "209      Newcombe       360       370       375       380       394       400   \n",
       "228     Mt Martha       520       545       550       570       590       600   \n",
       "\n",
       "     Sep 2022  Dec 2022  Mar 2023 postcode  \n",
       "98        460       460       478      NaN  \n",
       "110       600       600       600      NaN  \n",
       "155       380       380       380      NaN  \n",
       "162       419       450       500      NaN  \n",
       "209       410       420       425      NaN  \n",
       "228       600       600       600      NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_postcode = merged_df[merged_df['postcode'].isnull()]\n",
    "no_postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[merged_df['Suburb'] == 'Yarra Ranges', 'postcode'] = '3516'\n",
    "merged_df.loc[merged_df['Suburb'] == 'Mt Eliza', 'postcode'] = '3930'\n",
    "merged_df.loc[merged_df['Suburb'] == 'Wanagaratta', 'postcode'] = '3612'\n",
    "merged_df.loc[merged_df['Suburb'] == 'St Kilda Rd', 'postcode'] = '3182'\n",
    "merged_df.loc[merged_df['Suburb'] == 'Newcombe', 'postcode'] = '3219'\n",
    "merged_df.loc[merged_df['Suburb'] == 'Mt Martha', 'postcode'] = '3934'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df\n",
    "merged_df.to_csv(\"../data/curated/external/merged_price.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的文件已保存到：D:\\STUDYfile\\ADS\\P2\\notebook\\data2\\unique_postcode_price.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '../data/curated/external/merged_price.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Randomly drop duplicates in the 'postcode' column, keeping only the first occurrence\n",
    "data_unique = data.drop_duplicates(subset='postcode', keep='first')\n",
    "\n",
    "# Save the processed data to a new file, ensuring all 'postcode' values are unique\n",
    "output_path = '../data/curated/external/unique_postcode_price.csv'\n",
    "data_unique.to_csv(output_path, index=False)\n",
    "\n",
    "print(f'The processed file has been saved to: {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
