{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanbinh/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3517: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/yanbinh/data/final_property_1_data.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 1. Read the property CSV file\n",
    "property_file_path = '../data/curated/property/property_addresses_to_lat_lng.csv'\n",
    "property_data = pd.read_csv(property_file_path)\n",
    "\n",
    "# 2. Convert the latitude and longitude to geometric points\n",
    "property_data['geometry'] = property_data.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "# 3. Convert the DataFrame to a GeoDataFrame, specifying the coordinate system as WGS 84 (EPSG:4326)\n",
    "property_gdf = gpd.GeoDataFrame(property_data, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# 4. Load the SA2 geometry data\n",
    "file_path = '../data/raw/external/extracted_files/G01_VIC_GDA2020.gpkg'\n",
    "gdf_sa2 = gpd.read_file(file_path, layer='G01_SA2_2021_VIC')\n",
    "\n",
    "# 5. Convert the SA2 geometry data to the same coordinate system as the property data (WGS 84, EPSG:4326)\n",
    "gdf_sa2 = gdf_sa2.to_crs(epsg=4326)\n",
    "\n",
    "# 6. Perform a spatial join, merging the SA2 geometry data with the property data\n",
    "merged_gdf = gpd.sjoin(property_gdf, gdf_sa2[['SA2_CODE_2021', 'SA2_NAME_2021', 'geometry']], how='left', op='within')\n",
    "\n",
    "# 7. Save the results to a new CSV file\n",
    "output_file_path = '../data/curated/external/final_property_1_data.csv'\n",
    "merged_gdf.drop_duplicates(subset='address', inplace=True)\n",
    "merged_gdf[['price','address','beds','baths','parking', 'SA2_CODE_2021', 'SA2_NAME_2021','postcode']].to_csv(output_file_path, index=False)\n",
    "\n",
    "# Output the file path after completion\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "station_df = pd.read_csv('../data/raw/external/API/1/closest_station_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "station_df = station_df.drop(columns=['closest_station'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, station_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_station'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the four CSV files\n",
    "school_part_1_df = pd.read_csv('../data/raw/external/API/1/closest_school_distance_part_1.csv')\n",
    "school_part_2_df = pd.read_csv('../data/raw/external/API/1/closest_school_distance_part_2.csv')\n",
    "school_part_3_df = pd.read_csv('../data/raw/external/API/1/closest_school_distance_part_3.csv')\n",
    "school_part_4_df = pd.read_csv('../data/raw/external/API/1/closest_school_distance_part_4.csv')\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_school_df = pd.concat([school_part_1_df, school_part_2_df, school_part_3_df, school_part_4_df], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_school_df.to_csv('../data/raw/external/API/1/closest_school_distance_final_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "school_df = pd.read_csv('../data/raw/external/API/1/closest_school_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "school_df = school_df.drop(columns=['closest_school'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, school_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_school'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "police_df = pd.read_csv('../data/raw/external/API/1/closest_police_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "police_df = police_df.drop(columns=['closest_police'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, police_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_police'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "market_df = pd.read_csv('../data/raw/external/API/1/closest_market_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "market_df = market_df.drop(columns=['closest_market'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, market_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_market'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "library_df = pd.read_csv('../data/raw/external/API/1/closest_library_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "library_df = library_df.drop(columns=['closest_library'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, library_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_library'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "gym_df = pd.read_csv('../data/raw/external/API/1/closest_gym_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "gym_df = gym_df.drop(columns=['closest_gym'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, gym_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_gym'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "cbd_df = pd.read_csv('../data/raw/external/API/1/closest_cbd_distance_final_1.csv')\n",
    "property_df = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "\n",
    "# Drop the 'unknown' column from the first DataFrame\n",
    "cbd_df = cbd_df.drop(columns=['closest_gym'])\n",
    "\n",
    "# Merge the DataFrames using 'rent address' in one file and 'address' in the other\n",
    "merged_df = pd.merge(property_df, cbd_df, left_on='address', right_on='rent_address', how='inner')\n",
    "merged_df.rename(columns={'min_driving_distance_km':'closest_cbd'},inplace=True)\n",
    "merged_df = merged_df.drop(columns=['rent_address'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/curated/external/final_property_1_data.csv', index=False)\n",
    "\n",
    "print(\"Merged file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price                                        address  beds  baths  parking  \\\n",
      "0  282.0  2657/181 Exhibition Street MELBOURNE VIC 3000     1      1        1   \n",
      "1  325.0             35 King Street MYRTLEFORD VIC 3737     1      1        0   \n",
      "2  240.0      G15/58 Douglas Street NOBLE PARK VIC 3174     1      1        0   \n",
      "3  230.0          16/11 Bates Road WARRNAMBOOL VIC 3280     1      1        1   \n",
      "4  240.0      G03/58 Douglas Street NOBLE PARK VIC 3174     1      1        0   \n",
      "\n",
      "   SA2_CODE_2021         SA2_NAME_2021  postcode  closest_station  \\\n",
      "0      206041503  Melbourne CBD - East      3000             2.42   \n",
      "1      204031071            Myrtleford      3737            46.92   \n",
      "2      212041460     Noble Park - West      3174            13.02   \n",
      "3      217041480   Warrnambool - South      3280             3.99   \n",
      "4      212041460     Noble Park - West      3174            13.02   \n",
      "\n",
      "   closest_school  ...  closest_library  closest_gym  closest_cbd  \\\n",
      "0            0.64  ...             0.59         0.98         1.35   \n",
      "1            0.84  ...             1.19         0.14       284.95   \n",
      "2            0.71  ...             3.67         3.33        33.26   \n",
      "3            0.81  ...             3.71       100.86       253.37   \n",
      "4            0.71  ...             3.67         3.33        33.26   \n",
      "\n",
      "   2022 popluation  2023 popluation  ERP change %  Net overseas migration  \\\n",
      "0          10687.0          12408.0          16.1                  1907.0   \n",
      "1           4696.0           4663.0          -0.7                    20.0   \n",
      "2          19682.0          20206.0           2.7                   838.0   \n",
      "3          13323.0          13476.0           1.1                   180.0   \n",
      "4          19682.0          20206.0           2.7                   838.0   \n",
      "\n",
      "   Population density 2023 (persons/km2)  Median_tot_prsnl_inc_weekly  \\\n",
      "0                                15471.3                        884.0   \n",
      "1                                    8.4                        683.0   \n",
      "2                                 4214.3                        586.0   \n",
      "3                                  112.1                        761.0   \n",
      "4                                 4214.3                        586.0   \n",
      "\n",
      "   2021 popluation  \n",
      "0           9848.0  \n",
      "1           4745.0  \n",
      "2          19591.0  \n",
      "3          13337.0  \n",
      "4          19591.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read two CSV files\n",
    "df1 = pd.read_csv('../data/curated/external/final_property_1_data.csv')\n",
    "df2 = pd.read_csv('../data/curated/external/SA2/sa2final.csv')\n",
    "\n",
    "# Ensure the format of SA2 code is consistent, handle missing values, and convert to integer format\n",
    "df2['SA2 code'] = pd.to_numeric(df2['SA2 code'], errors='coerce').fillna(0).astype('Int64')\n",
    "\n",
    "# Perform a left join on 'SA2_CODE_2021' from df1 and 'SA2 code' from df2 (keep all rows from df1)\n",
    "merged_df = pd.merge(df1, df2, left_on='SA2_CODE_2021', right_on='SA2 code', how='left')\n",
    "\n",
    "# Remove any 'Unnamed' columns and drop unnecessary 'SA2 code' and 'SA2 name' columns\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.contains('^Unnamed')]\n",
    "merged_df = merged_df.drop(columns=['SA2 code', 'SA2 name'])\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "merged_df.to_csv('../data/curated/external/merged_property_sa2_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the merged data\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/merged_price_unique_postcode.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = '../data/curated/external/merged_price.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates based on the 'postcode' column\n",
    "df_unique = df.drop_duplicates(subset='postcode')\n",
    "\n",
    "# Save the deduplicated data to a CSV file\n",
    "output_path = '/mnt/data/merged_price_unique_postcode.csv'\n",
    "df_unique.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the output file path\n",
    "print(f\"Deduplicated file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price                                        address  beds  baths  parking  \\\n",
      "0  282.0  2657/181 Exhibition Street MELBOURNE VIC 3000     1      1        1   \n",
      "1  240.0      G15/58 Douglas Street NOBLE PARK VIC 3174     1      1        0   \n",
      "2  230.0          16/11 Bates Road WARRNAMBOOL VIC 3280     1      1        1   \n",
      "3  240.0      G03/58 Douglas Street NOBLE PARK VIC 3174     1      1        0   \n",
      "4  230.0              5 Morris DANDENONG NORTH VIC 3175     1      1        0   \n",
      "\n",
      "   SA2_CODE_2021         SA2_NAME_2021  postcode  closest_station  \\\n",
      "0      206041503  Melbourne CBD - East      3000             2.42   \n",
      "1      212041460     Noble Park - West      3174            13.02   \n",
      "2      217041480   Warrnambool - South      3280             3.99   \n",
      "3      212041460     Noble Park - West      3174            13.02   \n",
      "4      212041312       Dandenong North      3175            12.69   \n",
      "\n",
      "   closest_school  ...       Suburb  Mar 2021  Jun 2021  Sep 2021  Dec 2021  \\\n",
      "0            0.64  ...    Melbourne       380       369       350       350   \n",
      "1            0.71  ...   Noble Park       360       355       360       360   \n",
      "2            0.81  ...  Warrnambool       350       360       370       380   \n",
      "3            0.71  ...   Noble Park       360       355       360       360   \n",
      "4            0.84  ...    Dandenong       350       350       350       350   \n",
      "\n",
      "   Mar 2022  Jun 2022  Sep 2022  Dec 2022  Mar 2023  \n",
      "0       365       390       419       450       500  \n",
      "1       360       370       375       380       385  \n",
      "2       400       400       420       420       420  \n",
      "3       360       370       375       380       385  \n",
      "4       350       360       360       369       370  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV files\n",
    "df_property_sa2 = pd.read_csv('../data/curated/external/merged_property_sa2_data.csv')\n",
    "df_merged_price = pd.read_csv('../data/curated/external/merged_price.csv')\n",
    "\n",
    "# Merge based on the 'postcode' column\n",
    "merged_df = pd.merge(df_property_sa2, df_merged_price, on='postcode', how='inner')\n",
    "\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Remove duplicates based on the 'address' column\n",
    "merged_df_unique = merged_df.drop_duplicates(subset='address')\n",
    "\n",
    "# Display the deduplicated data\n",
    "print(merged_df_unique.head())  # Only display the first 5 rows\n",
    "\n",
    "# If you need to save the deduplicated data, you can use the following code:\n",
    "merged_df.to_csv('../data/curated/external/unique_merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_1 = pd.read_csv('../data/curated/external/unique_merged_data.csv')\n",
    "file_2 = pd.read_csv('../data/raw/external/school/postcode_school.csv')\n",
    "\n",
    "# Merge based on postcode column\n",
    "merged_data = pd.merge(file_1, file_2, left_on='postcode', right_on='Address_Postcode', how='inner')\n",
    "merged_data = merged_data.drop(columns=['Address_Postcode'])\n",
    "merged_data.to_csv('../data/curated/external/unique_merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据已保存为 merged_output_with_renamed_crime_columns.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the two CSV files\n",
    "file_1 = pd.read_csv('../data/curated/external/unique_merged_data.csv')\n",
    "lga_data = pd.read_csv('../data/curated/crime_by_year.csv')  # /home/yanbinh/data/LGA_crime_postcode(1).csv\n",
    "\n",
    "# Rename 'Postcode' column to 'postcode' for consistency\n",
    "lga_data.rename(columns={'Postcode': 'postcode'}, inplace=True)\n",
    "\n",
    "# Use pivot_table to transform 'Year' and 'Offence Count' into multiple columns, each year as a separate column\n",
    "lga_pivoted = lga_data.pivot(index='postcode', columns='Year', values='Offence Count').reset_index()\n",
    "\n",
    "# Rename the crime data columns to '2021crime', '2022crime', '2023crime', etc.\n",
    "lga_pivoted.columns = ['postcode'] + [f'{int(col)}crime' for col in lga_pivoted.columns if col != 'postcode']\n",
    "\n",
    "# Merge the crime data with the first file, matching on 'postcode'\n",
    "merged_data = pd.merge(file_1, lga_pivoted, on='postcode', how='left')\n",
    "\n",
    "# Save the merged data as a CSV file\n",
    "merged_data.to_csv('../data/curated/external/final_data.csv', index=False)\n",
    "\n",
    "print(\"Merged data has been saved as 'final_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('../data/curated/external/final_data.csv')\n",
    "file.rename(columns={'closest_cbd': 'minimum_distance_cbd'}, inplace=True)\n",
    "file.rename(columns={'closest_gym': 'minimum_distance_gym'}, inplace=True)\n",
    "file.rename(columns={'closest_library': 'minimum_distance_library'}, inplace=True)\n",
    "file.rename(columns={'closest_station': 'minimum_distance_station'}, inplace=True)\n",
    "file.rename(columns={'closest_police': 'minimum_distance_police'}, inplace=True)\n",
    "file.rename(columns={'closest_school': 'minimum_distance_school'}, inplace=True)\n",
    "file.rename(columns={'closest_market': 'minimum_distance_supermarket'}, inplace=True)\n",
    "file.to_csv('../data/curated/external/final_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
